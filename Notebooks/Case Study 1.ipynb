{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8202198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44a1ff1d",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc9ef070",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Dataset\\sub case study1\\client C customer reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2829adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grocery &amp; Gourmet Food_Beverages_Bottled Bever...</td>\n",
       "      <td>ONE OF THE HARDEST THINGS ABOUT LOW CARBING IT...</td>\n",
       "      <td>['MIX']</td>\n",
       "      <td>['Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Grocery &amp; Gourmet Food_Beverages_Bottled Bever...</td>\n",
       "      <td>This is as good as it gets for a point margari...</td>\n",
       "      <td>['point margarita']</td>\n",
       "      <td>['Positive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Grocery &amp; Gourmet Food_Beverages_Bottled Bever...</td>\n",
       "      <td>The strawberry margarita is all I have been ab...</td>\n",
       "      <td>['margarita' 'find']</td>\n",
       "      <td>['Positive' 'Positive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Grocery &amp; Gourmet Food_Beverages_Bottled Bever...</td>\n",
       "      <td>or they tasted just awful . I tried the origin...</td>\n",
       "      <td>['original Margarita mix']</td>\n",
       "      <td>['Positive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Grocery &amp; Gourmet Food_Beverages_Bottled Bever...</td>\n",
       "      <td>I then went a little nuts and ordered of just ...</td>\n",
       "      <td>['flavor']</td>\n",
       "      <td>['Positive']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                          unique_id  \\\n",
       "0           0      0  Grocery & Gourmet Food_Beverages_Bottled Bever...   \n",
       "1           2      2  Grocery & Gourmet Food_Beverages_Bottled Bever...   \n",
       "2           3      3  Grocery & Gourmet Food_Beverages_Bottled Bever...   \n",
       "3           5      5  Grocery & Gourmet Food_Beverages_Bottled Bever...   \n",
       "4           6      6  Grocery & Gourmet Food_Beverages_Bottled Bever...   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  ONE OF THE HARDEST THINGS ABOUT LOW CARBING IT...   \n",
       "1  This is as good as it gets for a point margari...   \n",
       "2  The strawberry margarita is all I have been ab...   \n",
       "3  or they tasted just awful . I tried the origin...   \n",
       "4  I then went a little nuts and ordered of just ...   \n",
       "\n",
       "                       aspect                sentiment  \n",
       "0                     ['MIX']              ['Neutral']  \n",
       "1         ['point margarita']             ['Positive']  \n",
       "2        ['margarita' 'find']  ['Positive' 'Positive']  \n",
       "3  ['original Margarita mix']             ['Positive']  \n",
       "4                  ['flavor']             ['Positive']  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83b9ecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147679, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d410fc6",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8aae95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_of_aspects(x):\n",
    "    ''' Counts the number of aspects in the aspect field of the dataset'''\n",
    "    x=x.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    x=x.strip().split(\"' '\")\n",
    "    if len(x)>1:\n",
    "        return len(x)\n",
    "    else:\n",
    "        if len(x[0].replace(\"'\",\"\"))==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "def extract_aspects(x):\n",
    "    ''' Extract aspects into a list'''\n",
    "    x=x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"' '\",\",\").replace(\"''\",\",\").replace(\"'\",\"\")\n",
    "    x=x.strip().split(\",\")\n",
    "    \n",
    "    return x\n",
    "     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59759809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_of_sentiments(x):\n",
    "    ''' Counts the number of sentiments in the sentiment field of the dataset'''\n",
    "    x=x.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    x=x.strip().split(\" \")\n",
    "    if len(x)>1:\n",
    "        return len(x)\n",
    "    else:\n",
    "        if len(x[0].replace(\"'\",\"\"))==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1891b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['num_of_sentiments']=dataset['sentiment'].apply(lambda x:count_number_of_sentiments(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e4f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['num_of_aspects']=dataset['aspect'].apply(lambda x:count_number_of_aspects(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d38e988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_sentiments\n",
       "1     64.186513\n",
       "2     18.075014\n",
       "0     12.298973\n",
       "3      4.276844\n",
       "4      0.887736\n",
       "5      0.198403\n",
       "6      0.052817\n",
       "7      0.011511\n",
       "8      0.007449\n",
       "10     0.002031\n",
       "9      0.002031\n",
       "11     0.000677\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18 percentage of records have sentiments missing\n",
    "dataset['num_of_sentiments'].value_counts()/len(dataset)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f2978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentiment']=dataset['sentiment'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0772a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['is_negative']=dataset['sentiment'].apply(lambda x: 1 if 'negative' in x  else 0)\n",
    "dataset['is_positive']=dataset['sentiment'].apply(lambda x: 1 if 'positive' in x  else 0)\n",
    "dataset['is_neutral']=dataset['sentiment'].apply(lambda x: 1 if 'neutral' in x  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd80f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21682161986470655\n",
      "0.21682161986470655\n",
      "0.2557303340353063\n"
     ]
    }
   ],
   "source": [
    "#class well balanced\n",
    "print(dataset.is_negative.sum()/len(dataset))\n",
    "print(dataset.is_negative.sum()/len(dataset))\n",
    "print(dataset.is_neutral.sum()/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ee8128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting review text into sentences\n",
    "dataset['split_reviewText_sentences']=dataset['reviewText'].apply(lambda x:nltk.tokenize.sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d747bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of sentences in each review text\n",
    "dataset['number_of_sentences']=dataset['split_reviewText_sentences'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994c8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the number of sentiments and sentences are same for each record\n",
    "dataset['diff_between_num_sentences_num_sentiments']=np.abs(dataset['number_of_sentences']-dataset['num_of_sentiments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "277319bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diff_between_num_sentences_num_sentiments\n",
       "0      39.134880\n",
       "1      38.898557\n",
       "2      12.761462\n",
       "3       4.597133\n",
       "4       2.028724\n",
       "5       0.966962\n",
       "6       0.526141\n",
       "7       0.352115\n",
       "8       0.218718\n",
       "9       0.142200\n",
       "10      0.100217\n",
       "11      0.069069\n",
       "12      0.054172\n",
       "13      0.033180\n",
       "14      0.021669\n",
       "15      0.014897\n",
       "17      0.012866\n",
       "16      0.011511\n",
       "18      0.010157\n",
       "19      0.006771\n",
       "20      0.005417\n",
       "23      0.004740\n",
       "21      0.004740\n",
       "28      0.003386\n",
       "30      0.002709\n",
       "25      0.002031\n",
       "27      0.002031\n",
       "29      0.001354\n",
       "22      0.001354\n",
       "35      0.001354\n",
       "26      0.000677\n",
       "74      0.000677\n",
       "24      0.000677\n",
       "81      0.000677\n",
       "121     0.000677\n",
       "41      0.000677\n",
       "37      0.000677\n",
       "31      0.000677\n",
       "33      0.000677\n",
       "32      0.000677\n",
       "56      0.000677\n",
       "34      0.000677\n",
       "38      0.000677\n",
       "128     0.000677\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diff_between_num_sentences_num_sentiments'].value_counts()/len(dataset)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462c91ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "147674    0\n",
       "147675    0\n",
       "147676    0\n",
       "147677    0\n",
       "147678    0\n",
       "Length: 147679, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(dataset['num_of_sentiments']-dataset['num_of_aspects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b767f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999458\n",
       "1    0.000535\n",
       "2    0.000007\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of sentiments and number of aspects are equal\n",
    "(np.abs(dataset['num_of_sentiments']-dataset['num_of_aspects'])).value_counts()/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ffd1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing aspects\n",
    "dataset['extracted_aspect']=dataset['aspect'].apply(lambda x:extract_aspects(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a784d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            [mix]\n",
       "1                [point margarita]\n",
       "2                [margarita, find]\n",
       "3         [original margarita mix]\n",
       "4                         [flavor]\n",
       "                    ...           \n",
       "147674                          []\n",
       "147675                [snack pies]\n",
       "147676                [snack pies]\n",
       "147677                          []\n",
       "147678                          []\n",
       "Name: extracted_aspect, Length: 147679, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['extracted_aspect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "afc3a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=dataset['extracted_aspect'].to_list()\n",
    "list_of_aspects=[item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1a9d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_aspects=set(list_of_aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dc58e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'compartment',\n",
       " 'water tank',\n",
       " 'these chocolate',\n",
       " 'turtle fudge',\n",
       " 'light natural',\n",
       " 'filling in the middle',\n",
       " 'cup of latte',\n",
       " 'properties',\n",
       " 'milky flavor',\n",
       " 'other',\n",
       " '! they',\n",
       " 'movie theater popcorn',\n",
       " 'ultra',\n",
       " 'bag of chips',\n",
       " 'mochi daifuku',\n",
       " 'sugary options',\n",
       " 'bottle opening',\n",
       " 'tapioca',\n",
       " 'hawaiian kona coffee',\n",
       " 'tea bag style',\n",
       " 'soy flour',\n",
       " 'salt and vinegar chips',\n",
       " 'castor oil',\n",
       " 'nutritional bar',\n",
       " 'to make',\n",
       " 'shrink wrap',\n",
       " 'baking soda',\n",
       " 'profit .',\n",
       " 'animal animal crackers',\n",
       " 'nutter butter sandwich cookies',\n",
       " 'mint leaves',\n",
       " ' coffee',\n",
       " 'wrapping papers',\n",
       " 'einkorn products',\n",
       " 'chocolate biscuits',\n",
       " 'bengal spice tea',\n",
       " 'catnip',\n",
       " 'roast coffees',\n",
       " 'chiller blocks',\n",
       " 'unclouded color',\n",
       " 'coffee flavored water',\n",
       " 'crap',\n",
       " 'total carbs',\n",
       " 'freshpak',\n",
       " 'echinacea one',\n",
       " 'loves these jelly beans',\n",
       " 'drinking container',\n",
       " 'rich chocolate filling and',\n",
       " 'affirmations',\n",
       " 'rosa',\n",
       " 'counter waiting',\n",
       " '12 pack',\n",
       " 'gift basket',\n",
       " 'green mountain blueberry coffee\\n french vanilla creamer',\n",
       " 'freshpak rooibos tea',\n",
       " 'arrival',\n",
       " 'folate',\n",
       " 'non decaf',\n",
       " 'saltines cuckoo egg',\n",
       " 'chip granola bar',\n",
       " 'curved design',\n",
       " 'box of crackers',\n",
       " 'the milk',\n",
       " 'flavorful',\n",
       " 'chocolate taste',\n",
       " 'sun dried tomato parmesan',\n",
       " 'amount of product',\n",
       " 'buttermint',\n",
       " 'love margaritas',\n",
       " 'base',\n",
       " 'colorado',\n",
       " 'mate drinks',\n",
       " 'patty',\n",
       " 'dinner parties',\n",
       " 'of condensed milk',\n",
       " 'christmas stocking stuffers',\n",
       " 'light butter',\n",
       " 'quality of the beans',\n",
       " 'tea mix',\n",
       " 'this applesauce',\n",
       " 'woody',\n",
       " 'assorted flavors',\n",
       " '. pleasing texture ',\n",
       " 'vanilla experience',\n",
       " 'wheat matzos',\n",
       " 'gloria jeans coffee',\n",
       " 'glass quart pitcher',\n",
       " 'in transit',\n",
       " 'hot chocolate drink',\n",
       " 'produt',\n",
       " 'arrive',\n",
       " 'assorted tea . twinings',\n",
       " 'as the flavor',\n",
       " 'dostawce',\n",
       " 'of soy',\n",
       " 'stocking',\n",
       " 'hum',\n",
       " 'sauce pan',\n",
       " 'the red bean is',\n",
       " 'design of',\n",
       " 'walnut syrup',\n",
       " 'gourmet microwavable popcorn',\n",
       " 'hair vitamins',\n",
       " 'tazo red bush tea',\n",
       " 'value and',\n",
       " 'pickled ginger',\n",
       " 'osem egg onion matzah',\n",
       " 'dark chocolate covered strawberries',\n",
       " 'return info',\n",
       " 'the case price',\n",
       " 'skiing',\n",
       " 'with raisins',\n",
       " 'rice milk',\n",
       " 'configuration',\n",
       " 'celestial teas',\n",
       " 'prescription pills',\n",
       " 'worship',\n",
       " 'pancake syrup',\n",
       " '. coffee cup',\n",
       " 'cherry lozenge',\n",
       " 'coke',\n",
       " 'caramel latte',\n",
       " 'meatloaf',\n",
       " 'sips',\n",
       " 'my favorite graham crackers',\n",
       " 'environmentally friendly bags',\n",
       " 'southern',\n",
       " 'brew choices',\n",
       " 'truffle pieces',\n",
       " 'centerpieces',\n",
       " 'wife',\n",
       " 'like drinks',\n",
       " 'serving cookies',\n",
       " 'gin',\n",
       " 'few flavors',\n",
       " 'paro',\n",
       " 'redbull sugarfree',\n",
       " 'handle',\n",
       " 'zico in the tetra pak',\n",
       " 'grapefruit soda',\n",
       " 'taste just like home',\n",
       " 'dark chocolate almonds',\n",
       " 'fats',\n",
       " 'macaroon',\n",
       " 'e foods',\n",
       " 'fratello',\n",
       " 'cello trays',\n",
       " 'electrolyte drink mix',\n",
       " 'coffee lovers',\n",
       " 'good',\n",
       " 'planet',\n",
       " 'yuban decaf',\n",
       " 'nori seaweed',\n",
       " 'provolone on toast',\n",
       " 'oriental',\n",
       " 'finish',\n",
       " 'van houtte french vanilla coffee',\n",
       " 'tasting flavor',\n",
       " 'surprising',\n",
       " 'single bag of chips',\n",
       " 'sleep aid',\n",
       " 'senso pods',\n",
       " 'thus the stars',\n",
       " 'diet black cherry sodas',\n",
       " 'metal taste',\n",
       " 'glass spray bottle',\n",
       " 'filtered water',\n",
       " 'delmonte fruit',\n",
       " 'elm bark',\n",
       " 'different tea varieties',\n",
       " 'leather',\n",
       " 'tiramisu dessert',\n",
       " '92',\n",
       " 'wonderful aroma',\n",
       " 'nut are',\n",
       " 'more strong black',\n",
       " 'coconut on top',\n",
       " 'candy shop',\n",
       " 'cold pack',\n",
       " 'metabolism',\n",
       " 'bag of',\n",
       " 'paperboard',\n",
       " 'trans fatty acids',\n",
       " 'custom blended morning coffee',\n",
       " 'strap',\n",
       " 'sugar free cookies',\n",
       " 'swiss miss cocoa',\n",
       " 'fire aroma',\n",
       " 'fruit ea sampler',\n",
       " 'poas',\n",
       " 'hazelnut creme',\n",
       " 'hint of soy',\n",
       " 'slice',\n",
       " 'waker upper',\n",
       " 'tri pack',\n",
       " 'sweetened condensed milk',\n",
       " 'pop corn light butter',\n",
       " 'orange gatorade',\n",
       " 'kirkland signature truffles',\n",
       " 'members',\n",
       " 'retailer',\n",
       " 'mix of sesame',\n",
       " 'foot',\n",
       " 'fresh limes',\n",
       " 'butter cookies',\n",
       " 'iced ones',\n",
       " 'box of dips & spreads',\n",
       " 'peanut butter crackers',\n",
       " 'kitchen cabinet',\n",
       " 'fusion',\n",
       " 'colored',\n",
       " 'priced source',\n",
       " 'birds',\n",
       " 'yeast extract',\n",
       " 'coconuts',\n",
       " 'coconut cakes',\n",
       " 'mandarin orange taste',\n",
       " 'peppermint candies',\n",
       " 'mineral water',\n",
       " 'probiotics',\n",
       " 'spot of',\n",
       " 'mellita version',\n",
       " 'tea teabags',\n",
       " 'fast shipping and great service',\n",
       " 'smoothie with bananas',\n",
       " 'customer service was',\n",
       " 'box of popcorn',\n",
       " 'different flavours',\n",
       " 'plain green tea',\n",
       " 'category',\n",
       " 'drakes',\n",
       " 'individual packets',\n",
       " 'sour ghettis',\n",
       " 'free shipping',\n",
       " 'sing',\n",
       " 'ranch flavors',\n",
       " 'glass size',\n",
       " 'goldfish crackers',\n",
       " 'tuna',\n",
       " 'soy lecithin in',\n",
       " 'spiced sweets',\n",
       " 'salt mix',\n",
       " 'cashew butter',\n",
       " 'fudge',\n",
       " 'carry dips',\n",
       " 'newman ginger',\n",
       " 'boiled stuff',\n",
       " 'barley hot drink',\n",
       " 'sprouted blue corn tortilla chips',\n",
       " 'serving sizes',\n",
       " 'gevalia pod machine',\n",
       " 'koala ones',\n",
       " '62mm pod',\n",
       " 'coffee system',\n",
       " 'rapidmailing',\n",
       " 'package size',\n",
       " 'distributor',\n",
       " 'bag of cookies',\n",
       " 'typical juice box',\n",
       " 'metromint',\n",
       " 'black cherry tea',\n",
       " 'quinoa chips',\n",
       " 'grits',\n",
       " 'bee packaging',\n",
       " 'good and price',\n",
       " 'warmth and',\n",
       " 'blend',\n",
       " 'earl greys',\n",
       " 'enkins',\n",
       " 'priced fortune cookies',\n",
       " 'kilogram',\n",
       " 'organic brand',\n",
       " 'usual diet fare',\n",
       " 'oreo taste',\n",
       " 'samples',\n",
       " 'tang taste',\n",
       " 'marshmallow surrounding the jam',\n",
       " 'mintiness',\n",
       " '16 oz mug',\n",
       " 'packing air bags',\n",
       " 'cows milk',\n",
       " 'potato tortilla chip',\n",
       " 'douwe egbert coffee',\n",
       " 'discs',\n",
       " 'durian',\n",
       " 'flour',\n",
       " 'froggies',\n",
       " 'outer bags',\n",
       " 'cheese products',\n",
       " 'oatcake',\n",
       " 'kernals',\n",
       " 'diabetes',\n",
       " 'truffette',\n",
       " 'anise oil',\n",
       " 'senseo coffee pots',\n",
       " 'sweet level',\n",
       " 'packaging method',\n",
       " 'marshmellows',\n",
       " 'animals',\n",
       " 'glass of juice',\n",
       " 'diet',\n",
       " 'nature valley',\n",
       " 'almond and dark chocolate',\n",
       " 'esseac formulas',\n",
       " 'specific flavors',\n",
       " 'butter cookie',\n",
       " 'crispyness that',\n",
       " 'grahams',\n",
       " 'discount coupon',\n",
       " 'grape ones',\n",
       " 'taste of lime',\n",
       " 'meringues',\n",
       " 'pizzelle cookie',\n",
       " 'perforations',\n",
       " 'there',\n",
       " 'orange peels',\n",
       " 'truly',\n",
       " 'gyokuro',\n",
       " 'cappuchino',\n",
       " 'dandelion root',\n",
       " 'banana ones',\n",
       " 'europe',\n",
       " '. coffee',\n",
       " 'tasting simple nutrient vitamin drink',\n",
       " 'jasmine green tea i',\n",
       " 'douwe egbert',\n",
       " 'traditional medicines',\n",
       " 'rings',\n",
       " 'healthy',\n",
       " 'wasa crackers',\n",
       " 'typical',\n",
       " '4',\n",
       " 'excellent tea',\n",
       " 'chilis',\n",
       " 'peanut butter fudge',\n",
       " 'subscription discounted',\n",
       " 'bubble tea is',\n",
       " 'decaf cocoa',\n",
       " 'nut nut',\n",
       " 'decent quality espresso',\n",
       " 'electrolites',\n",
       " 'cola',\n",
       " 'flax seed bars',\n",
       " 'hull less',\n",
       " 'instant coffee grounds',\n",
       " 'to transport',\n",
       " 'decaffeinated coffee pods',\n",
       " 'echinacea',\n",
       " 'packs',\n",
       " 'dosser',\n",
       " 'individual truffles',\n",
       " 'mochi covering',\n",
       " 'fabrics',\n",
       " 'apple other',\n",
       " 'biscuit powder',\n",
       " 'lard',\n",
       " 'leapin lemon cookies',\n",
       " 'taste sooo',\n",
       " 'gevalia coffees',\n",
       " 'sound',\n",
       " 'chocolates box',\n",
       " 'black licorice jelly beans',\n",
       " 'devonsheer rounds',\n",
       " 'einkorn',\n",
       " 'joint supplements',\n",
       " 'question',\n",
       " 'sharing police',\n",
       " 'words',\n",
       " 'chlorine',\n",
       " 'guacamole flavor',\n",
       " 'sahne',\n",
       " 'chocolate the',\n",
       " 'toffee flavor .',\n",
       " 'supply list',\n",
       " 'kona pod',\n",
       " 'gerds',\n",
       " 'robert flavors',\n",
       " 'vietnamese style ice coffee',\n",
       " 'turron',\n",
       " 'table water',\n",
       " 'this popcorn is',\n",
       " 'jet tea',\n",
       " 'torani syrups',\n",
       " 'zip lock bags',\n",
       " 'vegetable sound',\n",
       " 'america chocolate',\n",
       " 'overall effect',\n",
       " 'paris butter waffles',\n",
       " 'flavor pink',\n",
       " 'the nest taste',\n",
       " 'rice crackers',\n",
       " 'natural foods store',\n",
       " 'multiple flavors',\n",
       " 'brown rice snaps',\n",
       " 'sweet peppers ',\n",
       " 'chocolate toffee',\n",
       " 'taste without',\n",
       " 'dark roast coffee senseo pod',\n",
       " 'lavazza coffee',\n",
       " 'salt\\n sesame seeds',\n",
       " 'ship cusp expiry food',\n",
       " 'warmer',\n",
       " ' chocolate taste',\n",
       " 'sugar free oreo',\n",
       " 'good nutrional',\n",
       " 'measuring',\n",
       " 'low iodine',\n",
       " 'power start',\n",
       " 'teeth effect',\n",
       " 'divinity',\n",
       " '12 oz glass',\n",
       " 'zico water',\n",
       " 'original bawls',\n",
       " 'cranberry concentrate',\n",
       " 'ground coffee',\n",
       " 'love coffee ',\n",
       " 'neighborhood',\n",
       " 'irish coffees',\n",
       " 'mix of seasonings',\n",
       " 'part',\n",
       " 'pumpkin',\n",
       " 'flavores',\n",
       " 'goodness',\n",
       " 'aloe juice',\n",
       " 'nonnis biscotti',\n",
       " 'back of the package',\n",
       " 'cookie batter',\n",
       " 'green tea concentrate',\n",
       " '6s',\n",
       " 'ghirardelli s',\n",
       " 'bagel toasting',\n",
       " 'quality nuts',\n",
       " 'grog coffee',\n",
       " 'coconut thai tea',\n",
       " 'prime pantry',\n",
       " 'bake',\n",
       " 'shopping list',\n",
       " 'convenience',\n",
       " 'coffee ground',\n",
       " 'tapioca express',\n",
       " 'cardboard tub',\n",
       " 'scoop rate',\n",
       " 'peppermint teabag',\n",
       " 'creamer',\n",
       " 'cookie serving size',\n",
       " 'would',\n",
       " 'vita cappuccino',\n",
       " 'nantucket blend',\n",
       " 'ingredient popcorn',\n",
       " 'summertime drink',\n",
       " 'shopkeeper',\n",
       " 'any other tea',\n",
       " 'french roast variety',\n",
       " 'flavored candy',\n",
       " 'gag gifts',\n",
       " 'yummy morsels',\n",
       " 'sweet more',\n",
       " 'business',\n",
       " 'mixing drinks',\n",
       " 'atomic balls',\n",
       " 'akmak crackers',\n",
       " 'workout regimen',\n",
       " 'cheeseball',\n",
       " 'less fat',\n",
       " 'order details',\n",
       " 'moths',\n",
       " 'corned beef',\n",
       " 'shipping good',\n",
       " 'vegetable fat',\n",
       " 'chili flavor',\n",
       " 'wasa',\n",
       " 'sugar free drink mixes',\n",
       " 'blueberry flavor',\n",
       " 'meat pins',\n",
       " 'parts water',\n",
       " 'gify',\n",
       " 'reed ginger beer extra',\n",
       " 'celestial seasonings mandarin orange',\n",
       " 'onion flavors',\n",
       " 'taffy item',\n",
       " 'individual rice cakes',\n",
       " 'vue packs',\n",
       " 'and option',\n",
       " 'fruit flavored',\n",
       " 'marshmallow fluff',\n",
       " 'vanilla almond milk',\n",
       " '100 % arabica',\n",
       " 'sweet snack',\n",
       " 'combination of dark chocolate',\n",
       " 'gorilla',\n",
       " 'coconut sugar',\n",
       " 'apple chip',\n",
       " 'melon filling',\n",
       " 'new england coffee breakfast blend',\n",
       " 'passion fruit syrup',\n",
       " 'gift',\n",
       " 'van houtte french vanilla cups',\n",
       " 'to sour',\n",
       " 'shelves with apple',\n",
       " 'coffee filter',\n",
       " '100 tea bags',\n",
       " 'pilon gourmet',\n",
       " 'sweet treats',\n",
       " 'bene wafer company',\n",
       " 'yehuda matzo',\n",
       " 'krispy',\n",
       " 'brewed',\n",
       " 'pear taste',\n",
       " 'chips ahoy cookies',\n",
       " 'kona coffee blend',\n",
       " 'baguette',\n",
       " 'cardboard case',\n",
       " 'tea bag',\n",
       " 'butter wafter cookies',\n",
       " 'assam black tea',\n",
       " 'regular chamomile and peppermint',\n",
       " 'koku',\n",
       " 'healthy cookie',\n",
       " 'href kashi layered granola',\n",
       " 'diet coke',\n",
       " 'this twislers',\n",
       " 'product bang had',\n",
       " 'pumpkin spice taste',\n",
       " 'tings',\n",
       " 'jug of cookies',\n",
       " 'definition',\n",
       " 'mini meal',\n",
       " 'carrageenan',\n",
       " 'ingredient list palm oil',\n",
       " 'wicked jack cakes',\n",
       " 'back pain',\n",
       " 'matcha juice',\n",
       " 'photo',\n",
       " 'that',\n",
       " 'rare',\n",
       " 'hamburgers',\n",
       " 'baseline lipton tea',\n",
       " 'shipping rate',\n",
       " 'orville',\n",
       " 'appealing taste',\n",
       " 'hazelnut senseo pods',\n",
       " 'matcha',\n",
       " 'eleuthro root tea',\n",
       " 'delivery person',\n",
       " 'return option',\n",
       " 'slices',\n",
       " 'diet cream soda',\n",
       " 'food pouch design',\n",
       " 'gingerbread spice tea',\n",
       " 'parent',\n",
       " 'interior',\n",
       " 'solar power',\n",
       " 'cherry lemonade',\n",
       " 'brands',\n",
       " 'main character',\n",
       " '- dairy coffee creamers',\n",
       " 'saltines product',\n",
       " 'matzo',\n",
       " 'mid afternoon snack',\n",
       " 'goals',\n",
       " 'double chocolate cookies',\n",
       " 'details',\n",
       " 'favorable',\n",
       " 'doh',\n",
       " 'great pies',\n",
       " 'infuser',\n",
       " 'publix',\n",
       " 'sugar substitute',\n",
       " 'peanut flavor',\n",
       " 'cookie recipe',\n",
       " 'pump',\n",
       " 'and truffles',\n",
       " 'lime sour margarita mix',\n",
       " 'ginger teas',\n",
       " 'apple cider vinegar',\n",
       " 'soup',\n",
       " 'individual wrapped tea',\n",
       " 'fourths',\n",
       " 'favorite salsa',\n",
       " 'contrex',\n",
       " 'clear cubes',\n",
       " 'tortilla chips',\n",
       " 'mulberries',\n",
       " 'twins',\n",
       " 'moist',\n",
       " 'black',\n",
       " 'whole bean version',\n",
       " 'europeon',\n",
       " 'cockroach smell',\n",
       " 'chocolate coffee',\n",
       " ' lemongrass',\n",
       " 'liver cleanser',\n",
       " 'tasty snack',\n",
       " 'roast coffee pod',\n",
       " 'whites',\n",
       " 'mrs . field cookie',\n",
       " 'snap cap',\n",
       " 'mix with lemonade',\n",
       " 'lightness',\n",
       " 'cafecito',\n",
       " 'pretzel package',\n",
       " 'href stainless',\n",
       " '. these',\n",
       " 'firmness',\n",
       " 'rtiz cracker',\n",
       " 'language',\n",
       " 'folgers coffee',\n",
       " 'honeydew melon',\n",
       " 'tea drinkers',\n",
       " 'candy was',\n",
       " 'blueberry and strawberry ones',\n",
       " 'chardonnay brittle',\n",
       " 'flavor mix',\n",
       " 'this soup',\n",
       " 'french flavor',\n",
       " 'stuff and',\n",
       " 'belvita cookies',\n",
       " 'rumchata',\n",
       " 'flvor',\n",
       " 'strings',\n",
       " 'full bodied coffee',\n",
       " 'crema than other',\n",
       " 'keurig system',\n",
       " 'afternoon tea',\n",
       " 'ting ting',\n",
       " 'super saver shipping',\n",
       " 'amy',\n",
       " 'fine taste',\n",
       " '10oz . boxes',\n",
       " 'liquors',\n",
       " 'salt packets',\n",
       " 'nap',\n",
       " 'carried',\n",
       " 'bisque',\n",
       " 'dark roast version',\n",
       " 'anti',\n",
       " 'savannah golds',\n",
       " 'pale yellow',\n",
       " 'clarified butter',\n",
       " 'hot cocoa powder',\n",
       " 'gallon sizes',\n",
       " 'tea drinker',\n",
       " 'pumpkin wine',\n",
       " 'graham cracker style',\n",
       " 'tasting',\n",
       " 'adagio dessert teas',\n",
       " 'tootsie rolls assorted fruit rolls',\n",
       " 'shipping process',\n",
       " 'box of caramel',\n",
       " 'bezos',\n",
       " 'size granola bar',\n",
       " 'needle',\n",
       " 'the and',\n",
       " 'cinnamon roll',\n",
       " 'chip taste',\n",
       " 'crackers with',\n",
       " 'mixed with white wine',\n",
       " 'bigelow tea bags',\n",
       " 'spit salsas',\n",
       " 'a for',\n",
       " 'cookie jar',\n",
       " 'gummi frogs',\n",
       " 'frozen yogurt shop',\n",
       " 'inventory',\n",
       " 'americano',\n",
       " 'flavor selections',\n",
       " 'cookie packaging',\n",
       " 'shortbread cookie',\n",
       " 'facts',\n",
       " 'tension tamer',\n",
       " 'granola flours',\n",
       " 'gummies',\n",
       " 'butter balls',\n",
       " 'portafilter',\n",
       " 'almond butter',\n",
       " ' lemon ',\n",
       " 'white cheddar crisps',\n",
       " 'honey nut',\n",
       " 'jelly spreads',\n",
       " 'coffee pack',\n",
       " 'air freshener',\n",
       " 'walker toffees',\n",
       " 'decaffeinated tazo green tea with lotus flower',\n",
       " 'chocolat',\n",
       " 'gift card',\n",
       " 'pod design',\n",
       " 'price anyhow',\n",
       " 'orange slices',\n",
       " 'bag closure',\n",
       " 'patisseries',\n",
       " 'soap',\n",
       " 'drunken goat cheese',\n",
       " 'wagashi',\n",
       " 'happiness',\n",
       " 'this popcorn for',\n",
       " 'thailand',\n",
       " 'perfect potful',\n",
       " 'distance',\n",
       " 'also sent',\n",
       " 'tomatoe soup',\n",
       " 'diacetyls',\n",
       " 'chicory coffee',\n",
       " '2oz',\n",
       " 'products',\n",
       " 'soda pop',\n",
       " 'adding sugar',\n",
       " 'tea setting',\n",
       " 'douwe egberts medium roast pods',\n",
       " 'tuscan barbecue',\n",
       " 'kitchen table',\n",
       " 'medium roast',\n",
       " 'roast decaf',\n",
       " 'return window',\n",
       " 'crunchy peanut butter and',\n",
       " '20 oz',\n",
       " 'berries',\n",
       " 'there is no sweeteners',\n",
       " 'concentrated sucralose',\n",
       " 'liter jar',\n",
       " 'plane',\n",
       " 'milk powder',\n",
       " '12 ounce bottle',\n",
       " 'cane sugar and grape juice',\n",
       " 'kidney',\n",
       " 'folgers cafe latte mocha',\n",
       " 'addictive',\n",
       " 'cameo',\n",
       " 'plain peppermint teas',\n",
       " 'apt',\n",
       " 'while',\n",
       " 'communication seller',\n",
       " 'sour belts',\n",
       " 'padding',\n",
       " 'juicing',\n",
       " 'ice coffee',\n",
       " 'chai latte tea',\n",
       " 'the aluminum .',\n",
       " 'disc',\n",
       " 'cafe mocha cappuccino',\n",
       " 'juice plus protein powder',\n",
       " 'wax',\n",
       " 'mochi',\n",
       " 'straight',\n",
       " 'plus shipping',\n",
       " 'blue berry tea',\n",
       " 'cocoa',\n",
       " 'this is priced',\n",
       " 'pelican',\n",
       " 'cinnamon apple spice',\n",
       " 'vietnamese coffee',\n",
       " 'twinnings',\n",
       " 'size box',\n",
       " 'nutrition profile',\n",
       " 'sea salt variety',\n",
       " 'cookeis',\n",
       " 'korean snack',\n",
       " 'rosemary',\n",
       " 'glitter',\n",
       " 'spice flavors',\n",
       " 'veggie chips',\n",
       " 'metal flap seal',\n",
       " 'hors oeuvres',\n",
       " 'fake',\n",
       " 'truffels',\n",
       " 'trung',\n",
       " 'ca',\n",
       " 'dusting',\n",
       " 'blue chips',\n",
       " 'no sugar cookie',\n",
       " 'plate',\n",
       " 'individual',\n",
       " 'sodium dehydroacetate',\n",
       " 'order snack',\n",
       " 'stars the',\n",
       " 'expecting',\n",
       " 'roll',\n",
       " 'pool',\n",
       " 'plain potato chips',\n",
       " 'green beans',\n",
       " 'frying pan',\n",
       " 'luxurious',\n",
       " 'twinings teas',\n",
       " 'baby white rice',\n",
       " 'pro stat 64',\n",
       " 'belgian chocolate',\n",
       " 'plastic air bags',\n",
       " 'borsari',\n",
       " 'and this price on',\n",
       " 'hydrating',\n",
       " 'retail price',\n",
       " 'truth',\n",
       " 'tazo chai group',\n",
       " 'good on ham',\n",
       " 'tea line',\n",
       " 'hard candy candies',\n",
       " 'size portion',\n",
       " 'add olive oil',\n",
       " 'range',\n",
       " 'hot chocolate',\n",
       " 'the smell',\n",
       " 'hard candies',\n",
       " 'spray bottle',\n",
       " 'jasmine tea bags',\n",
       " 'earl grey supreme',\n",
       " 'tablespoons',\n",
       " 'the milk chocolate',\n",
       " 'chocolate covered potato chips',\n",
       " 'original postum',\n",
       " 'quality assurance',\n",
       " 'breakfast food',\n",
       " 'ginger chews',\n",
       " 'chili flavors .',\n",
       " 'suggested',\n",
       " 'availability',\n",
       " 'of coconut water',\n",
       " 'vietnamese coffee filter',\n",
       " 'morning sickness',\n",
       " 'spice mixture',\n",
       " 'jelly belly flavors',\n",
       " 'holiday treat',\n",
       " 'mama',\n",
       " 'edges of the paper',\n",
       " 'black teas pu erh',\n",
       " 'pumpkin teas',\n",
       " 'nubs',\n",
       " 'automatic re order system',\n",
       " 'mate versions',\n",
       " 'root vegetable chips',\n",
       " 'shopping experience',\n",
       " 'erin baker breakfast cookies',\n",
       " 'combonation',\n",
       " 'chocolate candy ever',\n",
       " 'assorted fruit flavors',\n",
       " 'japantown mall',\n",
       " 'with almonds',\n",
       " 'lolipop',\n",
       " 'our delicous',\n",
       " 'sesame cookies',\n",
       " 'shipped',\n",
       " 'roasted coffee beans',\n",
       " 'tamarinds',\n",
       " 'chicory root granules',\n",
       " 'poured',\n",
       " 'car',\n",
       " 'powerbars',\n",
       " 'mesh',\n",
       " 'itself',\n",
       " 'guarantees',\n",
       " 'fruit leather',\n",
       " 'corn product',\n",
       " 'count',\n",
       " 'red hot candies',\n",
       " 'white russian',\n",
       " 'sesame and seaweed flavor',\n",
       " 'one',\n",
       " 'green tea aspect',\n",
       " 'symbol',\n",
       " 'sugarfree oreo',\n",
       " 'del',\n",
       " 'cookie cutter',\n",
       " 'lightly salted',\n",
       " 'peach tea infuser',\n",
       " 'raspberry teas',\n",
       " 'chamomile flavor',\n",
       " 'strainer',\n",
       " 'sugar coating',\n",
       " 'really nice',\n",
       " 'panda biscuits',\n",
       " 'selections of flavors',\n",
       " 'drip coffee',\n",
       " 'banana split type',\n",
       " 'decaf chai tea',\n",
       " 'fragile',\n",
       " 'snack foods',\n",
       " 'trung nguyen coffee',\n",
       " 'both',\n",
       " 'whippet',\n",
       " 'prep',\n",
       " 'cuisines',\n",
       " 'good fast',\n",
       " 'guayaki yerba mate',\n",
       " 'orange flavoring',\n",
       " 'cow dung',\n",
       " 'expirations',\n",
       " 'cream soda',\n",
       " 'red teas',\n",
       " 'cappuccino',\n",
       " 'foil bags',\n",
       " 'extra virgin olive oil',\n",
       " 'jucies',\n",
       " 'chai blends',\n",
       " 'manufacturer',\n",
       " 'chilaquiles',\n",
       " 'cinnabon cup',\n",
       " 'streits',\n",
       " 'rum syrup',\n",
       " 'polysorbate',\n",
       " 'pineapple sherbet and coconut milk',\n",
       " 'it tastes',\n",
       " 'cupboard',\n",
       " 'suits',\n",
       " 'powered vacuum unit',\n",
       " 'oolong teas',\n",
       " 'shaker',\n",
       " 'coconut ones',\n",
       " 'size bars',\n",
       " 'spelt',\n",
       " 'texture oreos',\n",
       " 'butter toffee cups',\n",
       " 'coated',\n",
       " 'buttery',\n",
       " 'rice rollers',\n",
       " 'thai teas',\n",
       " 'scalloped oysters',\n",
       " 'regular vanilla',\n",
       " 'individual sealed tea bags',\n",
       " 'probably',\n",
       " 'fruit variety',\n",
       " 'lemon pepper',\n",
       " 'inexpensive .',\n",
       " 'for espresso',\n",
       " 'long',\n",
       " 'paper',\n",
       " 'senseo medium roast',\n",
       " 'the more subtle',\n",
       " 'cashew milk',\n",
       " 'celery flavored soda',\n",
       " 'tail end pieces',\n",
       " 'money back guarantee',\n",
       " 'turkish almonds',\n",
       " 'orange soda taste',\n",
       " 'authentic ramune experience',\n",
       " 'and the flavor',\n",
       " 'ginger\\n black pepper',\n",
       " 'mandarin orange flavored soda',\n",
       " 'kola',\n",
       " 'trying new flavors',\n",
       " 'french roast blend',\n",
       " 'tea well',\n",
       " 'bengal spice bag',\n",
       " 'segafredo',\n",
       " 'milk chocolate orange sticks',\n",
       " 'from shopping',\n",
       " 'original hard candies',\n",
       " 'pinapples',\n",
       " 'tastykake delivery man',\n",
       " 'organic aloe vera juice',\n",
       " 'about miles',\n",
       " 'sesame blue goodness',\n",
       " 'tirimisu',\n",
       " 'tasted like bacon',\n",
       " 'multi seed',\n",
       " 'robust coffee',\n",
       " 'original cookie',\n",
       " 'manju',\n",
       " 'el duende cookies',\n",
       " 'microwaving',\n",
       " 'fig bars',\n",
       " 'junk food',\n",
       " 'gummy candies',\n",
       " 'starter',\n",
       " 'fruit',\n",
       " 'apricot applesauce',\n",
       " 'top crackers',\n",
       " 'coconut palm',\n",
       " 'nope',\n",
       " 'lovely experience',\n",
       " 'pack of cigarettes',\n",
       " 'price buying',\n",
       " 'fruit bowls',\n",
       " 'oatmeal pies',\n",
       " 'newest flavors',\n",
       " 'quality pannettones',\n",
       " 'oregano',\n",
       " 'pussy',\n",
       " 'receiver',\n",
       " 'nabisco saltine crackers',\n",
       " 'variety package',\n",
       " 'there cocktail',\n",
       " 'feeling',\n",
       " 'stevia powder',\n",
       " 'lance',\n",
       " 'mean',\n",
       " 'tv remote',\n",
       " 'juice concentrate',\n",
       " 'whey protein supplement',\n",
       " 'coconut macaroon tea',\n",
       " 'pick me up',\n",
       " 'version',\n",
       " 'honey grahams',\n",
       " 'cherry 7up',\n",
       " '. great',\n",
       " 'wheat taste',\n",
       " 'popcorn lovers',\n",
       " 'amino acids',\n",
       " 'adults',\n",
       " 'good flavor',\n",
       " 'pinapple sodas',\n",
       " 'orange tummies',\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bc11678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17731"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of aspectsa\n",
    "len(set_of_aspects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "515ff292",
   "metadata": {},
   "source": [
    "### Pre-processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ba7644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "080deb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4b39341",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"Great TASTE . GMO FREE ! ! ! ! ! I only use water , other use fruit and such but I do not have that option at work . Water works great .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9bd1b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0aefc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    text=''.join([i for i in text if not i.isdigit()]) #remove digit    \n",
    "    text=re.sub(r'[^\\w\\s]', '', text) # remove special characters/puctuations\n",
    "    text=\" \".join(text.split()) #remove extra spaces\n",
    "    doc=nlp(text)\n",
    "    text=[token.lemma_ for token in doc]\n",
    "    text=' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d318d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64f484f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d0df6891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 147679/147679 [15:14<00:00, 161.54it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset['cleaned_text']=dataset['reviewText'].progress_map(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7efd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruning rows with 0 sentiments\n",
    "dataset=dataset[dataset['num_of_sentiments']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29682f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                   0\n",
       "index                                        0\n",
       "unique_id                                    0\n",
       "reviewText                                   0\n",
       "aspect                                       0\n",
       "sentiment                                    0\n",
       "num_of_sentiments                            0\n",
       "num_of_aspects                               0\n",
       "is_negative                                  0\n",
       "is_positive                                  0\n",
       "is_neutral                                   0\n",
       "split_reviewText_sentences                   0\n",
       "number_of_sentences                          0\n",
       "diff_between_num_sentences_num_sentiments    0\n",
       "extracted_aspect                             0\n",
       "cleaned_text                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no nans\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bad1d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Dataset\\sub case study1\\case1_cleaned_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e626318",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Dataset\\sub case study1\\case1_cleaned_set.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aec602c4",
   "metadata": {},
   "source": [
    "### Modellinng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01f56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac69de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(dataset,random_state=32,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d768e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,valid_df=train_test_split(train_df,random_state=32,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa2dc11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to load a model of incompatible/unknown type. 'C:\\Users\\ATREYA~1.BAN\\AppData\\Local\\Temp\\tfhub_modules\\d760773f85f64fc84ae0b47310f7cfe3bcec4868' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bert_preprocess \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(\u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m bert_encoder \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[39m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m       set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow_hub\\module_v2.py:107\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    102\u001b[0m saved_model_pbtxt_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    103\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mas_bytes(module_path),\n\u001b[0;32m    104\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mas_bytes(tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(saved_model_path) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(saved_model_pbtxt_path)):\n\u001b[1;32m--> 107\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrying to load a model of incompatible/unknown type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m contains neither \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m nor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    109\u001b[0m                    (module_path, tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB,\n\u001b[0;32m    110\u001b[0m                     tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m options:\n\u001b[0;32m    113\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mgetattr\u001b[39m(tf, \u001b[39m\"\u001b[39m\u001b[39msaved_model\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mLoadOptions\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Trying to load a model of incompatible/unknown type. 'C:\\Users\\ATREYA~1.BAN\\AppData\\Local\\Temp\\tfhub_modules\\d760773f85f64fc84ae0b47310f7cfe3bcec4868' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'."
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ffe9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessed_text = bert_preprocess(text_input)\n",
    "    outputs = bert_encoder(preprocessed_text)\n",
    "    # Neural network layers\n",
    "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "    l = tf.keras.layers.Dense(3, activation='sigmoid', name=\"output\")(l)\n",
    "    # Use inputs and outputs to construct a final model\n",
    "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5538e83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m=\u001b[39mcreate_model()\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m text_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstring, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m preprocessed_text \u001b[39m=\u001b[39m bert_preprocess(text_input)\n\u001b[1;32m----> 4\u001b[0m outputs \u001b[39m=\u001b[39m bert_encoder(preprocessed_text)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Neural network layers\u001b[39;00m\n\u001b[0;32m      6\u001b[0m l \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.1\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m\"\u001b[39m)(outputs[\u001b[39m'\u001b[39m\u001b[39mpooled_output\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bert_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e009b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'index', 'unique_id', 'reviewText',\n",
       "       'aspect', 'sentiment', 'num_of_sentiments', 'num_of_aspects',\n",
       "       'is_negative', 'is_positive', 'is_neutral',\n",
       "       'split_reviewText_sentences', 'number_of_sentences',\n",
       "       'diff_between_num_sentences_num_sentiments', 'extracted_aspect',\n",
       "       'cleaned_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15165105",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=valid_df['cleaned_text'],valid_df[['is_negative', 'is_positive','is_neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e11378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1984/1984 [==============================] - 17575s 9s/step - loss: 1.0724 - accuracy: 0.5835 - val_loss: 1.0078 - val_accuracy: 0.6241\n",
      "Epoch 2/3\n",
      "1984/1984 [==============================] - 23830s 12s/step - loss: 1.0171 - accuracy: 0.6178 - val_loss: 0.9662 - val_accuracy: 0.6497\n",
      "Epoch 3/3\n",
      "1984/1984 [==============================] - 16874s 9s/step - loss: 1.0041 - accuracy: 0.6277 - val_loss: 0.9660 - val_accuracy: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193ba445070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "epochs=3\n",
    "batch_size=32\n",
    "model.fit(train_df['cleaned_text'],train_df[['is_negative', 'is_positive','is_neutral']],validation_data=validation_data,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb59f4e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#model.save_weights(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Artifacts\\model_weights\")\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39matreya.bandyopad\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mNLP_L2\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mArtifacts\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmodel_weights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#model.save_weights(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Artifacts\\model_weights\")\n",
    "model.load_weights(r\"C:\\Users\\atreya.bandyopad\\Documents\\NLP_L2\\Artifacts\\model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705f3d5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_df[\u001b[39m'\u001b[39m\u001b[39mcleaned_text\u001b[39m\u001b[39m'\u001b[39m],test_df[[\u001b[39m'\u001b[39m\u001b[39mis_negative\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mis_positive\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mis_neutral\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_df['cleaned_text'],test_df[['is_negative', 'is_positive','is_neutral']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a847d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
